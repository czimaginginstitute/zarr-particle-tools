"""
Standalone script with modular functions to generate required files for subtomogram extraction from a CryoET Data Portal run.

Note that in the context of the tomograms.star and "individual tomograms" star files, these are analagous with tiltseries.star files
that might be generated by other tools that similarily provide these star files as input to (RELION) subtomogram extraction.

Generates:
- particles.star file for the specified runs and annotations.
- tomograms.star file for the tiltseries.
- tiltseries/*.star files for each tiltseries in the run.
"""

# TODO: add multithreading/multiprocessing and caching and local joins to speed up graphql queries
# TODO: add tests - with all possible parameters and edge cases
import argparse
import logging
import json
import time
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor, as_completed
import pandas as pd
import numpy as np
import starfile
from tqdm import tqdm
from cryoet_data_portal import Client, Annotation, AnnotationShape, Alignment, PerSectionAlignmentParameters, PerSectionParameters, Frame, AnnotationFile, TiltSeries, Tomogram
from generate.constants import (
    THREAD_POOL_WORKER_COUNT,
    DEFAULT_AMPLITUDE_CONTRAST,
    TOMO_HAND_DEFAULT_VALUE,
    PARTICLES_DF_COLUMNS,
    OPTICS_DF_COLUMNS,
    INDIVIDUAL_TOMOGRAM_COLUMNS,
    INDIVIDUAL_TOMOGRAM_CTF_COLUMNS,
    INDIVIDUAL_TOMOGRAM_ALN_COLUMNS,
    NOISY_LOGGERS,
)
from generate.helpers import TqdmLoggingHandler, suppress_noisy_loggers, get_data

logger = logging.getLogger(__name__)
client = Client()


# TODO: implement local joins and caching for tomograms
def get_particles_df_optics_df_from_shape(
    annotation_shape: AnnotationShape, annotation_files: list[AnnotationFile], alignment_list: list[Alignment], tiltseries_list: list[TiltSeries]
) -> tuple[pd.DataFrame, pd.DataFrame]:
    """
    Returns a particles dataframe and optics dataframe from a Point / OrientedPoint annotation shape in RELION 5 format.
    Args:
        annotation_shape (AnnotationShape): The annotation shape object containing point data.
        annotation_files (list[AnnotationFile]): List of annotation files associated with the shape.
        alignment_list (list[Alignment]): List of alignments associated with the shape.
        tiltseries_list (list[TiltSeries]): List of tiltseries associated with the shape.
    Returns:
        tuple: A tuple containing the optics dataframe and particles dataframe.
    """
    optics_df = pd.DataFrame(columns=OPTICS_DF_COLUMNS)
    particles_df = pd.DataFrame(columns=PARTICLES_DF_COLUMNS)
    particles_list = []

    for i, file in enumerate(annotation_files, start=1):
        alignment = next((a for a in alignment_list if a.id == file.alignment_id), None)
        tiltseries = next((t for t in tiltseries_list if t.id == alignment.tiltseries_id), None)
        if not alignment or not alignment.per_section_alignments or not tiltseries or not tiltseries.per_section_parameters:
            logger.error(
                f'[Run {alignment.run_id}, Annotation {annotation_shape.annotation_id}] Missing alignment or tiltseries information "{annotation_shape.annotation.object_name}" (shape ID {annotation_shape.id}, file ID {file.id}). Skipping.'
            )
            continue

        tomogram_data = set((t.size_x, t.size_y, t.size_z, t.voxel_spacing) for t in file.tomogram_voxel_spacing.tomograms)

        if len(tomogram_data) != 1:
            logger.error(
                f"[Run {alignment.run_id}, Annotation {annotation_shape.annotation_id}] Expected tomograms to have the same size and voxel size, but found {len(tomogram_data)} unique values. Skipping this file."
            )
            continue
        tomogram_data = list(tomogram_data)[0]

        # optics
        optics_group_name = f"run_{tiltseries.run_id}_tiltseries_{tiltseries.id}"
        optics_df.loc[len(optics_df)] = {
            "rlnOpticsGroup": i,
            "rlnOpticsGroupName": optics_group_name,
            "rlnSphericalAberration": tiltseries.spherical_aberration_constant,
            "rlnVoltage": tiltseries.acceleration_voltage,
            "rlnAmplitudeContrast": DEFAULT_AMPLITUDE_CONTRAST,
            "rlnTomoTiltSeriesPixelSize": tiltseries.pixel_spacing,
        }

        # particles
        tomo_name = f"run_{alignment.run_id}_tiltseries_{tiltseries.id}_alignment_{alignment.id}"

        json_data = get_data(file.s3_path)
        json_point_data = [json.loads(line) for line in json_data.splitlines() if line.strip()]

        pixel_coordinates = [(d["location"]["x"], d["location"]["y"], d["location"]["z"]) for d in json_point_data]
        centered_coordinates = [
            (
                (p[0] - tomogram_data[0] / 2) * tomogram_data[3],
                (p[1] - tomogram_data[1] / 2) * tomogram_data[3],
                (p[2] - tomogram_data[2] / 2) * tomogram_data[3],
            )
            for p in pixel_coordinates
        ]

        current_particles_list = [
            {
                "rlnTomoName": tomo_name,
                "rlnCoordinateX": p[0],
                "rlnCoordinateY": p[1],
                "rlnCoordinateZ": p[2],
                "rlnAngleRot": 0,
                "rlnAngleTilt": 0,
                "rlnAnglePsi": 0,
                "rlnCenteredCoordinateXAngst": c[0],
                "rlnCenteredCoordinateYAngst": c[1],
                "rlnCenteredCoordinateZAngst": c[2],
                "rlnOpticsGroupName": optics_group_name,
                "rlnOpticsGroup": i,
            }
            for p, c in zip(pixel_coordinates, centered_coordinates)
        ]
        particles_list.extend(current_particles_list)

    particles_df = pd.DataFrame(particles_list, columns=particles_df.columns)

    return optics_df, particles_df


def get_particles_df_optics_df(annotation_ids: list[int], use_tqdm: bool = True) -> tuple[pd.DataFrame, pd.DataFrame]:
    """
    Creates particles and optics dataframes necessary for a particles.star file from CryoET Data Portal annotations.
    Args:
        annotation_ids (list[int]): List of annotation IDs to pull data from.
        use_tqdm (bool): Whether to use tqdm for progress tracking (and print it out to the console).
    Returns:
        tuple: A tuple containing the optics dataframe and particles dataframe (combined from all Point and OrientedPoint annotations).
    """
    logger.info(f"Pulling annotations with IDs {annotation_ids} from the CryoET Data Portal ...")
    all_optics_dfs, all_particles_dfs = [], []

    # TODO: cache this with other gql queries
    annotation_shapes: list[AnnotationShape] = AnnotationShape.find(
        client, query_filters=[AnnotationShape.annotation_id._in(annotation_ids), AnnotationShape.shape_type._in(["Point", "OrientedPoint"])]
    )
    annotation_files: list[AnnotationFile] = AnnotationFile.find(client, query_filters=[AnnotationFile.annotation_shape_id._in([shape.id for shape in annotation_shapes])])
    alignments: list[Alignment] = Alignment.find(client, query_filters=[Alignment.id._in([file.alignment_id for file in annotation_files])])
    tiltseries: list[TiltSeries] = TiltSeries.find(client, query_filters=[TiltSeries.id._in([alignment.tiltseries_id for alignment in alignments])])
    shapes_to_files = {shape: [file for file in annotation_files if file.annotation_shape_id == shape.id] for shape in annotation_shapes}
    with ThreadPoolExecutor(max_workers=THREAD_POOL_WORKER_COUNT) as thread_pool:
        futures = [thread_pool.submit(get_particles_df_optics_df_from_shape, ann_shape, ann_files, alignments, tiltseries) for ann_shape, ann_files in shapes_to_files.items()]

        pbar = tqdm(total=len(futures), desc="Downloading particle data") if use_tqdm else None
        for fut in as_completed(futures):
            optics_df, particles_df = fut.result()
            all_optics_dfs.append(optics_df)
            all_particles_dfs.append(particles_df)
            if pbar:
                pbar.update(1)

        if pbar:
            pbar.close()

    # filter out empty dataframes
    all_optics_dfs = [df for df in all_optics_dfs if not df.empty]
    all_particles_dfs = [df for df in all_particles_dfs if not df.empty]

    if not all_optics_dfs or not all_particles_dfs:
        raise ValueError("No valid optics or particles data found. Ensure the annotations contain valid Point or OrientedPoint shapes, and their datasets have tiltseries and alignment information.")

    # combine all optics and particles dataframes, remove duplicates, sort by optics group name, and assign optics group numbers
    combined_optics_df = pd.concat(all_optics_dfs, ignore_index=True).drop_duplicates()
    combined_particles_df = pd.concat(all_particles_dfs, ignore_index=True).drop_duplicates()
    for df in [combined_optics_df, combined_particles_df]:
        # convert "run_XXXXX_tiltseries_YYYYY" format to integers for sorting
        df["rlnOpticsGroupNameInt"] = df["rlnOpticsGroupName"].apply(lambda x: (int(x.split("_")[1]), int(x.split("_")[3])))
        df.sort_values(by="rlnOpticsGroupNameInt", inplace=True)
        df.drop(columns=["rlnOpticsGroupNameInt"], inplace=True)
    combined_optics_df["rlnOpticsGroup"] = np.arange(1, len(combined_optics_df) + 1)
    combined_particles_df["rlnOpticsGroup"] = combined_particles_df["rlnOpticsGroupName"].map(combined_optics_df.set_index("rlnOpticsGroupName")["rlnOpticsGroup"])

    return combined_optics_df, combined_particles_df


# TODO: Refactor this to decouple it from get_particles_df_optics_df output dataframes
def get_tomograms_df(optics_df: pd.DataFrame, particles_df: pd.DataFrame) -> tuple[pd.DataFrame, list[int]]:
    """
    Returns a dataframe for the tomograms.star file from the optics and particles dataframes.
    Args:
        optics_df (pd.DataFrame): The optics dataframe containing the optics group information.
        particles_df (pd.DataFrame): The particles dataframe containing the particle information.
    Returns:
        tuple: A tuple containing the tomograms dataframe and a list of alignment IDs.
    """
    only_tomo_names_and_optics_groups = particles_df[["rlnTomoName", "rlnOpticsGroupName"]].drop_duplicates()
    # merge with optics_df to get rlnVoltage, rlnSphericalAberration, rlnAmplitudeContrast, and rlnTomoTiltSeriesPixelSize
    tomograms_df = only_tomo_names_and_optics_groups.merge(optics_df, on="rlnOpticsGroupName", how="left")
    tomograms_df["rlnMicrographOriginalPixelSize"] = tomograms_df["rlnTomoTiltSeriesPixelSize"]
    tomograms_df["rlnTomoHand"] = TOMO_HAND_DEFAULT_VALUE
    tomograms_df["rlnTomoTiltSeriesStarFile"] = tomograms_df["rlnTomoName"].apply(lambda x: f"tiltseries/{x}.star")

    # TODO: cache this
    # reliant on the fact that rlnTomoName is in the format of "run_XXXXX_tiltseries_YYYYY_alignment_ZZZZZ"
    tomograms_df["alignment_id"] = tomograms_df["rlnTomoName"].apply(lambda x: int(x.split("_")[-1]))
    alignment_ids = tomograms_df["alignment_id"].unique().tolist()
    tomograms: list[Tomogram] = Tomogram.find(client, query_filters=[Tomogram.id._in(alignment_ids)])
    tomograms_dimensions = pd.DataFrame(
        columns=["alignment_id", "rlnTomoSizeX", "rlnTomoSizeY", "rlnTomoSizeZ"],
        data=[(tomogram.alignment_id, tomogram.size_x, tomogram.size_y, tomogram.size_z) for tomogram in tomograms],
    )
    # check that every alignment_id has a tomogram size
    missing_ids = set(alignment_ids) - set(tomograms_dimensions["alignment_id"])
    if missing_ids:
        logger.error(f"Missing tomogram sizes for alignment IDs: {missing_ids}.")
    # check that every alignment_id has only one tomogram size
    tomograms_dimensions = tomograms_dimensions.drop_duplicates()
    unique_alignment_ids = tomograms_dimensions.drop_duplicates(subset=["alignment_id"])
    if len(unique_alignment_ids) != len(tomograms_dimensions):
        logger.error(f"Multiple tomogram sizes found for alignment IDs: {set(tomograms_dimensions['alignment_id']) - set(unique_alignment_ids['alignment_id'])}.")

    tomograms_df = tomograms_df.merge(tomograms_dimensions, on="alignment_id", how="left")
    tomograms_df.drop(columns=["alignment_id"], inplace=True)
    return tomograms_df, alignment_ids


def in_plane_rotation_to_tilt_axis_rotation(rotation_matrix: list[list[float]]) -> float:
    np_matrix = np.array(rotation_matrix)
    return np.degrees(np.arctan2(np_matrix[1, 0], np_matrix[0, 0]))


def generate_individual_tomogram_starfile(alignment: Alignment, output_dir: Path) -> tuple[pd.DataFrame, str]:
    """
    Generates an individual tomogram star file for the given alignment.
    Args:
        alignment (Alignment): The alignment object containing the tiltseries and per-section parameters.
        output_dir (Path): The directory where the individual tomogram star file will be saved.
    Returns:
        tuple: A tuple containing the individual tomogram dataframe and the tomogram name.
    """
    tiltseries = alignment.tiltseries
    per_section_parameters: list[PerSectionParameters] = PerSectionParameters.find(client, query_filters=[PerSectionParameters.tiltseries_id == tiltseries.id])
    per_section_alignment_parameters: list[PerSectionAlignmentParameters] = PerSectionAlignmentParameters.find(client, query_filters=[PerSectionAlignmentParameters.alignment_id == alignment.id])
    frames: list[Frame] = Frame.find(client, query_filters=[Frame.run_id == alignment.run_id])

    if len(per_section_parameters) != len(per_section_alignment_parameters):
        logger.error(
            f"[Run {alignment.run_id}, TiltSeries {tiltseries.id}, Alignment {alignment.id}] Mismatch between CTF and alignment parameters {len(per_section_parameters)} CTF != {len(per_section_alignment_parameters)} alignment parameters. Skipping this alignment."
        )
        return None, None

    per_section_parameters_df = pd.DataFrame(columns=INDIVIDUAL_TOMOGRAM_CTF_COLUMNS)
    for param in per_section_parameters:
        frame = next((f for f in frames if f.id == param.frame_id), None)
        per_section_parameters_df.loc[len(per_section_parameters_df)] = {
            "z_index": param.z_index,
            "acquisition_order": frame.acquisition_order + 1,  # match RELION's 1-based indexing
            "rlnDefocusU": param.major_defocus,
            "rlnDefocusV": param.minor_defocus,
            "rlnDefocusAngle": param.astigmatic_angle,
            "rlnPhaseShift": param.phase_shift,
            "rlnCtfMaxResolution": param.max_resolution,
            "rlnMicrographPreExposure": frame.accumulated_dose,
        }

    # TODO: incorporate param.tilt_offset and param.x_rotation_offset (and same for AreTomo3 alpha & beta)
    per_section_alignment_parameters_df = pd.DataFrame(
        columns=INDIVIDUAL_TOMOGRAM_ALN_COLUMNS,
        data=[
            {
                "z_index": param.z_index,
                "rlnTomoXTilt": param.volume_x_rotation,
                "rlnTomoYTilt": param.tilt_angle,
                "rlnTomoZRot": in_plane_rotation_to_tilt_axis_rotation(np.array(param.in_plane_rotation)),
                "rlnTomoXShiftAngst": param.x_offset,
                "rlnTomoYShiftAngst": param.y_offset,
            }
            for param in per_section_alignment_parameters
        ],
    )

    individual_tomogram_df = pd.merge(per_section_parameters_df, per_section_alignment_parameters_df, on="z_index", how="outer")
    if len(individual_tomogram_df) != len(per_section_parameters_df):
        logger.error(
            f"[Run {alignment.run_id}, TiltSeries {tiltseries.id}, Alignment {alignment.id}] Mismatch between CTF and alignment parameters after merge {len(individual_tomogram_df)} merged != {len(per_section_parameters_df)} CTF != {len(per_section_alignment_parameters_df)} alignment parameters. Skipping this alignment."
        )
        return None, None

    # reorder rows and columns to match RELION format
    individual_tomogram_df.sort_values(by="acquisition_order", inplace=True)
    individual_tomogram_df["rlnMicrographName"] = individual_tomogram_df["acquisition_order"].apply(lambda x: f"{str(int(x))}@{tiltseries.s3_omezarr_dir}")
    individual_tomogram_df = individual_tomogram_df.drop(columns=["z_index", "acquisition_order"])
    individual_tomogram_df = individual_tomogram_df[INDIVIDUAL_TOMOGRAM_COLUMNS]

    if individual_tomogram_df.isna().any().any():
        logger.error(
            f"[Run {alignment.run_id}, TiltSeries {tiltseries.id}, Alignment {alignment.id}] Data contains NA values. This can cause issues with RELION subtomogram extraction. Please check the star file."
        )

    tomo_name = f"run_{alignment.run_id}_tiltseries_{tiltseries.id}_alignment_{alignment.id}"
    output_path = output_dir / "tiltseries" / f"{tomo_name}.star"
    starfile.write({tomo_name: individual_tomogram_df}, output_path, overwrite=True)
    logger.debug(f"[Run {alignment.run_id}, TiltSeries {tiltseries.id}, Alignment {alignment.id}] Wrote individual tomogram star file to {output_path}")

    return individual_tomogram_df, tomo_name


def generate_individual_tomogram_starfiles(alignment_ids: list[int], output_dir: Path, use_tqdm: bool = True) -> list[pd.DataFrame]:
    """
    Generates individual tomogram star files for each alignment ID.
    Args:
        alignment_ids (list[int]): List of alignment IDs to generate individual tomogram star files for.
        output_dir (Path): Directory where the individual tomogram star files will be saved.
        use_tqdm (bool): Whether to use tqdm for progress tracking (and print it out to the console).
    Returns:
        list[pd.DataFrame]: List of DataFrames containing the individual tomogram data.
    """
    logger.info(f"Generating individual tomogram star files in {output_dir} ...")
    all_alignments: list[Alignment] = Alignment.find(client, query_filters=[Alignment.id._in(alignment_ids)])
    individual_tomograms_dfs = []
    tomo_names = []

    with ThreadPoolExecutor(max_workers=THREAD_POOL_WORKER_COUNT) as thread_pool:
        futures = [thread_pool.submit(generate_individual_tomogram_starfile, alignment, output_dir) for alignment in all_alignments]

        pbar = tqdm(total=len(futures), desc="Generating individual tomogram star files") if use_tqdm else None
        for fut in as_completed(futures):
            individual_tomogram_df, tomo_name = fut.result()
            if individual_tomogram_df is not None:
                individual_tomograms_dfs.append(individual_tomogram_df)
                tomo_names.append(tomo_name)
            if pbar:
                pbar.update(1)

        if pbar:
            pbar.close()

    return individual_tomograms_dfs, tomo_names


def generate_starfiles_from_annotation_ids(annotation_ids: list[int], output_dir: Path, use_tqdm: bool = True) -> tuple[Path, Path]:
    """
    Generates particles.star, tomograms.star, and individual tomogram star files from the given annotation IDs.
    Args:
        annotation_ids (list[int]): List of annotation IDs to generate star files from.
        output_dir (Path): Directory where the star files will be saved.
        use_tqdm (bool): Whether to use tqdm for progress tracking (and print it out to the console).
    Returns:
        tuple: A tuple containing the paths to the generated particles.star, tomograms.star, and the tiltseries folder.
    """
    start_time = time.time()
    optics_df, particles_df = get_particles_df_optics_df(annotation_ids, use_tqdm=use_tqdm)
    tomograms_df, alignment_ids = get_tomograms_df(optics_df, particles_df)
    _, tomo_names = generate_individual_tomogram_starfiles(alignment_ids, output_dir, use_tqdm=use_tqdm)
    # filter out invalid tomograms from optics, particles, and tomograms dataframes
    particles_df = particles_df[particles_df["rlnTomoName"].isin(tomo_names)]
    tomograms_df = tomograms_df[tomograms_df["rlnTomoName"].isin(tomo_names)]
    particles_df_optics_groups = particles_df["rlnOpticsGroupName"].unique()
    tomograms_df_optics_groups = tomograms_df["rlnOpticsGroupName"].unique()
    if set(particles_df_optics_groups) != set(tomograms_df_optics_groups):
        logger.error(
            f"Optics groups in particles ({particles_df_optics_groups}) and tomograms ({tomograms_df_optics_groups}) do not match. This may cause issues with RELION subtomogram extraction."
        )
    optics_df = optics_df[optics_df["rlnOpticsGroupName"].isin(particles_df_optics_groups)]

    # write files
    particles_path = output_dir / "particles.star"
    tomograms_path = output_dir / "tomograms.star"
    tiltseries_folder_path = output_dir / "tiltseries"
    starfile.write({"optics": optics_df, "particles": particles_df}, particles_path, overwrite=True)
    starfile.write({"global": tomograms_df}, tomograms_path, overwrite=True)
    logger.info(f"Wrote {len(optics_df)} optics group(s) and {len(particles_df)} particle(s) to {output_dir / 'particles.star'}")
    logger.info(f"Wrote {len(tomograms_df)} tomogram(s) to {output_dir / 'tomograms.star'}")

    end_time = time.time()
    logger.info(f"Finished generating star files in {end_time - start_time:.2f} seconds.")

    return particles_path, tomograms_path, tiltseries_folder_path


def generate_starfiles(annotation_ids: list[int], run_ids: list[str], annotation_names: list[str], output_dir: Path, debug: bool = False, use_tqdm: bool = True) -> tuple[Path, Path]:
    """
    Validates and resolves annotation IDs or names, and generates star files for the specified runs and annotations (calls generate_starfiles_from_annotation_ids).
    Args:
        annotation_ids (list[int]): List of annotation IDs to generate star files from.
        run_ids (list[str]): List of run IDs to filter annotations by.
        annotation_names (list[str]): List of annotation names to filter annotations by.
        output_dir (Path): Directory where the star files will be saved.
        use_tqdm (bool): Whether to use tqdm for progress tracking (and print it out to the console).
    Returns:
        tuple: A tuple containing the paths to the generated particles.star, tomograms.star, and the tiltseries folder.
    """
    if annotation_ids is None and annotation_names is None:
        raise ValueError("Either annotation_ids or annotation_names must be provided.")

    if use_tqdm:
        handler = TqdmLoggingHandler()
        handler.setFormatter(logging.Formatter("%(asctime)s - %(levelname)s - %(message)s"))
        logger.addHandler(handler)
        logger.propagate = False

    if debug:
        logger.setLevel(logging.DEBUG)

    suppress_noisy_loggers(NOISY_LOGGERS)

    (output_dir / "tiltseries").mkdir(parents=True, exist_ok=True)

    # TODO: allow for both to be provided, but do additional filtering
    if annotation_ids:
        if annotation_names:
            raise ValueError("Both annotation_ids and annotation_names provided. These parameters are mutually exclusive.")
        if run_ids:
            raise ValueError("Both annotation_ids and run_id provided. These parameters are mutually exclusive.")
        return generate_starfiles_from_annotation_ids(annotation_ids, output_dir, use_tqdm=use_tqdm)
    else:
        # get annotation id from object name
        resolved_annotation_ids = []
        for object_name in annotation_names:
            query_filters = [Annotation.object_name.ilike(f"%{object_name}%")]
            if run_ids:
                query_filters.append((Annotation.run_id._in(run_ids)))
            annotation: list[Annotation] = Annotation.find(client, query_filters)
            if annotation:
                ids = [a.id for a in annotation]
                resolved_annotation_ids.extend(ids)
                logger.debug(f"Found annotation IDs for '{object_name}': {ids}")
            else:
                logger.error(f"Annotation with name '{object_name}' not found{f" in runs {run_ids}" if run_ids else ''}.")

        resolved_annotation_ids = list(set(resolved_annotation_ids))
        if not resolved_annotation_ids:
            raise ValueError("No valid annotation IDs found.")
        return generate_starfiles_from_annotation_ids(resolved_annotation_ids, output_dir, use_tqdm=use_tqdm)


def main():
    parser = argparse.ArgumentParser(description="Generate star files needed for subtomogram extraction from a CryoET Data Portal run.")
    parser.add_argument("--run-ids", type=str, nargs="*", help="ID of the CryoET Data Portal run.")
    parser.add_argument("--annotation-ids", type=int, nargs="*", help="ID(s) of the annotation(s) to use for generating the star file.")
    parser.add_argument("--annotation-names", type=str, nargs="*", help="Name(s) of the annotation object(s) to use for generating the star file.")
    parser.add_argument("--output-dir", type=Path, required=True, help="Directory where star files will be saved.")
    parser.add_argument("--debug", action="store_true", help="Enable debug logging.")

    args = parser.parse_args()

    generate_starfiles(run_ids=args.run_ids, annotation_ids=args.annotation_ids, annotation_names=args.annotation_names, output_dir=args.output_dir, debug=args.debug, use_tqdm=True)


if __name__ == "__main__":
    main()

# Example usage:
# python generate/generate_starfile.py --run-ids 16463 --annotation-names ribosome --output-dir tests/output/data_portal_16363_ribosome
