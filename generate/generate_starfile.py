"""
Standalone script with modular functions to generate required files for subtomogram extraction from a CryoET Data Portal run.

Note that in the context of the tomograms.star and "individual tomograms" star files, these are analagous with tiltseries.star files
that might be generated by other tools that similarily provide these star files as input to (RELION) subtomogram extraction.

Generates:
- particles.star file for the specified runs and annotations.
- tomograms.star file for the tiltseries.
- tiltseries/*.star files for each tiltseries in the run.
"""

# TODO: add tests - with all possible parameters and edge cases
import argparse
import logging
import json
import time
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor, as_completed

import pandas as pd
import numpy as np
import starfile
import mrcfile
import cryoet_data_portal as cdp
from tqdm import tqdm

from generate.constants import (
    THREAD_POOL_WORKER_COUNT,
    TILTSERIES_MRCS_PLACEHOLDER,
    TILTSERIES_URI_RELION_COLUMN,
    DEFAULT_AMPLITUDE_CONTRAST,
    TOMO_HAND_DEFAULT_VALUE,
    PARTICLES_DF_COLUMNS,
    OPTICS_DF_COLUMNS,
    INDIVIDUAL_TOMOGRAM_COLUMNS,
    INDIVIDUAL_TOMOGRAM_CTF_COLUMNS,
    INDIVIDUAL_TOMOGRAM_ALN_COLUMNS,
    NOISY_LOGGERS,
)
from generate.helpers import TqdmLoggingHandler, suppress_noisy_loggers, get_data
import generate.cdp_cache as cdp_cache
import utils.args_common as args_common

logger = logging.getLogger(__name__)


def get_particles_df_optics_df_from_shape(
    annotation_file: cdp.AnnotationFile, alignment_dict: dict[int, cdp.Alignment], tiltseries_dict: dict[int, cdp.TiltSeries]
) -> tuple[pd.DataFrame, pd.DataFrame]:
    """
    Returns a particles dataframe and optics dataframe from Point / OrientedPoint annotation files.
    Args:
        annotation_file (cdp.AnnotationFile): The annotation file associated with the shape.
        alignment_dict (dict[int, cdp.Alignment]): Dictionary of alignments associated with the shape.
        tiltseries_dict (dict[int, cdp.TiltSeries]): Dictionary of tiltseries associated with the shape.
    Returns:
        tuple: A tuple containing the optics dataframe and particles dataframe.
    """
    optics_df = pd.DataFrame(columns=OPTICS_DF_COLUMNS)
    particles_df = pd.DataFrame(columns=PARTICLES_DF_COLUMNS)

    alignment = alignment_dict.get(annotation_file.alignment_id)
    tiltseries = tiltseries_dict.get(alignment.tiltseries_id) if alignment else None
    if not alignment or not cdp_cache.get_per_section_alignments_by_alignment_id(alignment.id) or not tiltseries or not cdp_cache.get_per_section_parameters_by_tiltseries_id(tiltseries.id):
        logger.error(f"[Run {alignment.run_id}, Annotation File {annotation_file.id}] Missing alignment or tiltseries information. Skipping file.")
        return optics_df, particles_df

    tomogram_data = set(
        (tomogram.size_x, tomogram.size_y, tomogram.size_z, tomogram.voxel_spacing)
        for tomograms in cdp_cache.get_tomograms_by_alignment_id_and_voxel_spacing_id((alignment.id, annotation_file.tomogram_voxel_spacing_id)).values()
        for tomogram in tomograms
    )

    if len(tomogram_data) != 1:
        logger.error(f"[Run {alignment.run_id}, Annotation File {annotation_file.id}] Expected tomograms to have the same size and voxel size, but found {len(tomogram_data)} unique values.")
        return optics_df, particles_df
    tomogram_data = list(tomogram_data)[0]

    # optics
    optics_group_name = f"run_{tiltseries.run_id}_tiltseries_{tiltseries.id}"
    optics_df.loc[0] = {
        "rlnOpticsGroup": 1,
        "rlnOpticsGroupName": optics_group_name,
        "rlnSphericalAberration": tiltseries.spherical_aberration_constant,
        "rlnVoltage": tiltseries.acceleration_voltage,
        "rlnAmplitudeContrast": DEFAULT_AMPLITUDE_CONTRAST,
        "rlnTomoTiltSeriesPixelSize": tiltseries.pixel_spacing,
    }

    # particles
    tomo_name = f"run_{alignment.run_id}_tiltseries_{tiltseries.id}_alignment_{alignment.id}_spacing_{annotation_file.tomogram_voxel_spacing_id}"

    json_data = get_data(annotation_file.s3_path)
    json_point_data = [json.loads(line) for line in json_data.splitlines() if line.strip()]

    pixel_coordinates = [(d["location"]["x"], d["location"]["y"], d["location"]["z"]) for d in json_point_data]
    centered_coordinates = [
        (
            (p[0] - tomogram_data[0] / 2) * tomogram_data[3],
            (p[1] - tomogram_data[1] / 2) * tomogram_data[3],
            (p[2] - tomogram_data[2] / 2) * tomogram_data[3],
        )
        for p in pixel_coordinates
    ]

    particles_list = [
        {
            "rlnTomoName": tomo_name,
            "rlnCoordinateX": p[0],
            "rlnCoordinateY": p[1],
            "rlnCoordinateZ": p[2],
            "rlnAngleRot": 0,
            "rlnAngleTilt": 0,
            "rlnAnglePsi": 0,
            "rlnCenteredCoordinateXAngst": c[0],
            "rlnCenteredCoordinateYAngst": c[1],
            "rlnCenteredCoordinateZAngst": c[2],
            "rlnOpticsGroupName": optics_group_name,
            "rlnOpticsGroup": 1,
        }
        for p, c in zip(pixel_coordinates, centered_coordinates)
    ]
    particles_df = pd.DataFrame(particles_list, columns=particles_df.columns)

    return optics_df, particles_df


def get_particles_df_optics_df(annotation_files: list[cdp.AnnotationFile], use_tqdm: bool = True) -> tuple[pd.DataFrame, pd.DataFrame]:
    """
    Creates particles and optics dataframes necessary for a particles.star file from CryoET Data Portal annotations.
    Args:
        annotation_files (list[AnnotationFile]): List of annotation files to process.
        use_tqdm (bool): Whether to use tqdm for progress tracking (and print it out to the console).
    Returns:
        tuple: A tuple containing the optics dataframe and particles dataframe (combined from all Point and OrientedPoint annotations).
    """
    logger.info(f"Pulling annotation files from the CryoET Data Portal ...")
    all_optics_dfs, all_particles_dfs = [], []

    alignments = cdp_cache.get_alignments([file.alignment_id for file in annotation_files])
    tiltseries = cdp_cache.get_tiltseries([alignment.tiltseries_id for alignment in alignments.values()])
    with ThreadPoolExecutor(max_workers=THREAD_POOL_WORKER_COUNT) as thread_pool:
        futures = [thread_pool.submit(get_particles_df_optics_df_from_shape, ann_files, alignments, tiltseries) for ann_files in annotation_files]

        pbar = tqdm(total=len(futures), desc="Downloading particle data") if use_tqdm else None
        for fut in as_completed(futures):
            optics_df, particles_df = fut.result()
            if optics_df.empty or particles_df.empty:
                continue
            all_optics_dfs.append(optics_df)
            all_particles_dfs.append(particles_df)
            if pbar:
                pbar.update(1)

        if pbar:
            pbar.close()

    # filter out empty dataframes
    all_optics_dfs = [df for df in all_optics_dfs if not df.empty]
    all_particles_dfs = [df for df in all_particles_dfs if not df.empty]

    if not all_optics_dfs or not all_particles_dfs:
        raise ValueError("No valid optics or particles data found. Ensure the annotations contain valid Point or OrientedPoint shapes, and their datasets have tiltseries and alignment information.")

    # combine all optics and particles dataframes, remove duplicates, sort by optics group name, and assign optics group numbers
    combined_optics_df = pd.concat(all_optics_dfs, ignore_index=True).drop_duplicates()
    combined_particles_df = pd.concat(all_particles_dfs, ignore_index=True).drop_duplicates()
    for df in [combined_optics_df, combined_particles_df]:
        # convert "run_XXXXX_tiltseries_YYYYY" format to integers for sorting
        df["rlnOpticsGroupNameInt"] = df["rlnOpticsGroupName"].apply(lambda x: (int(x.split("_")[1]), int(x.split("_")[3])))
        df.sort_values(by="rlnOpticsGroupNameInt", inplace=True)
        df.drop(columns=["rlnOpticsGroupNameInt"], inplace=True)
    combined_optics_df["rlnOpticsGroup"] = np.arange(1, len(combined_optics_df) + 1)
    combined_particles_df["rlnOpticsGroup"] = combined_particles_df["rlnOpticsGroupName"].map(combined_optics_df.set_index("rlnOpticsGroupName")["rlnOpticsGroup"])

    return combined_optics_df, combined_particles_df


def get_tomograms_df(optics_df: pd.DataFrame, particles_df: pd.DataFrame) -> tuple[pd.DataFrame, list[tuple[int, int]]]:
    """
    Returns a dataframe for the tomograms.star file from the optics and particles dataframes.
    Args:
        optics_df (pd.DataFrame): The optics dataframe containing the optics group information.
        particles_df (pd.DataFrame): The particles dataframe containing the particle information.
    Returns:
        tuple: A tuple containing the tomograms dataframe and a list of alignment IDs.
    """
    only_tomo_names_and_optics_groups = particles_df[["rlnTomoName", "rlnOpticsGroupName"]].drop_duplicates()
    # merge with optics_df to get rlnVoltage, rlnSphericalAberration, rlnAmplitudeContrast, and rlnTomoTiltSeriesPixelSize
    tomograms_df = only_tomo_names_and_optics_groups.merge(optics_df, on="rlnOpticsGroupName", how="left")
    tomograms_df["rlnMicrographOriginalPixelSize"] = tomograms_df["rlnTomoTiltSeriesPixelSize"]
    tomograms_df["rlnTomoHand"] = TOMO_HAND_DEFAULT_VALUE
    tomograms_df["rlnTomoTiltSeriesStarFile"] = tomograms_df["rlnTomoName"].apply(lambda x: f"tiltseries/{x}.star")

    # reliant on the fact that rlnTomoName is in the format of "run_WWWW_tiltseries_XXXX_alignment_YYYY_spacing_ZZZZ"
    tomograms_df["alignment_id"] = tomograms_df["rlnTomoName"].apply(lambda x: int(x.split("_")[-3]))
    tomograms_df["voxel_spacing_id"] = tomograms_df["rlnTomoName"].apply(lambda x: int(x.split("_")[-1]))
    alignment_ids = tomograms_df["alignment_id"].unique().tolist()
    voxel_spacing_ids = tomograms_df["voxel_spacing_id"].unique().tolist()
    tomograms_mapping = cdp_cache.get_tomograms_by_alignment_id_and_voxel_spacing_id(zip(alignment_ids, voxel_spacing_ids))
    tomograms_dimensions = pd.DataFrame(
        columns=["alignment_id", "voxel_spacing_id", "rlnTomoSizeX", "rlnTomoSizeY", "rlnTomoSizeZ"],
        data=[(tomogram.alignment_id, tomogram.tomogram_voxel_spacing_id, tomogram.size_x, tomogram.size_y, tomogram.size_z) for tomograms in tomograms_mapping.values() for tomogram in tomograms],
    )
    tomograms_dimensions.drop_duplicates(inplace=True)
    if len(tomograms_dimensions) != len(tomograms_dimensions[["alignment_id", "voxel_spacing_id"]].drop_duplicates()):
        raise ValueError("Multiple tomogram dimensions found for the same alignment ID and voxel spacing ID. This is not supported.")

    tomograms_df = tomograms_df.merge(tomograms_dimensions, on=["alignment_id", "voxel_spacing_id"], how="left")
    tomograms_df.drop(columns=["alignment_id", "voxel_spacing_id"], inplace=True)
    return tomograms_df, list(zip(alignment_ids, voxel_spacing_ids))


def in_plane_rotation_to_tilt_axis_rotation(rotation_matrix: list[list[float]]) -> float:
    np_matrix = np.array(rotation_matrix)
    return np.degrees(np.arctan2(np_matrix[1, 0], np_matrix[0, 0]))


def generate_individual_tomogram_starfile(alignment: cdp.Alignment, voxel_spacing: cdp.TomogramVoxelSpacing, output_dir: Path) -> tuple[pd.DataFrame, str]:
    """
    Generates an individual tomogram star file for the given alignment and voxel spacing.
    Args:
        alignment (Alignment): The alignment object containing the tiltseries and per-section parameters.
        voxel_spacing (TomogramVoxelSpacing): The voxel spacing object for the tomogram.
        output_dir (Path): The directory where the individual tomogram star file will be saved.
    Returns:
        tuple: A tuple containing the individual tomogram dataframe and the tomogram name.
    """
    tiltseries = list(cdp_cache.get_tiltseries(alignment.tiltseries_id).values())[0]
    per_section_parameters = list(cdp_cache.get_per_section_parameters_by_tiltseries_id(tiltseries.id).values())[0]
    per_section_alignment_parameters = list(cdp_cache.get_per_section_alignments_by_alignment_id(alignment.id).values())[0]
    frames = list(cdp_cache.get_frames_by_run_id(alignment.run_id).values())[0]

    if len(per_section_parameters) != len(per_section_alignment_parameters):
        raise ValueError(
            f"[Run {alignment.run_id}, TiltSeries {tiltseries.id}, Alignment {alignment.id}] Mismatch between CTF and alignment parameters {len(per_section_parameters)} CTF != {len(per_section_alignment_parameters)} alignment parameters."
        )

    per_section_parameters_df = pd.DataFrame(columns=INDIVIDUAL_TOMOGRAM_CTF_COLUMNS)
    for param in per_section_parameters:
        frame = next((f for f in frames if f.id == param.frame_id), None)
        per_section_parameters_df.loc[len(per_section_parameters_df)] = {
            "z_index": param.z_index,
            "acquisition_order": frame.acquisition_order + 1,  # match RELION's 1-based indexing
            "rlnDefocusU": param.major_defocus,
            "rlnDefocusV": param.minor_defocus,
            "rlnDefocusAngle": param.astigmatic_angle,
            "rlnPhaseShift": param.phase_shift,
            "rlnCtfMaxResolution": param.max_resolution,
            "rlnMicrographPreExposure": frame.accumulated_dose,
        }

    per_section_alignment_parameters_df = pd.DataFrame(
        columns=INDIVIDUAL_TOMOGRAM_ALN_COLUMNS,
        data=[
            {
                "z_index": param.z_index,
                "rlnTomoXTilt": param.volume_x_rotation,  # param.x_rotation offset (AreTomo3 beta) is not applied, as per AreTomo3 convention
                "rlnTomoYTilt": param.tilt_angle,  # already accounts for any tilt offset (AreTomo3 alpha)
                "rlnTomoZRot": in_plane_rotation_to_tilt_axis_rotation(np.array(param.in_plane_rotation)),
                "rlnTomoXShiftAngst": param.x_offset,
                "rlnTomoYShiftAngst": param.y_offset,
            }
            for param in per_section_alignment_parameters
        ],
    )

    individual_tomogram_df = pd.merge(per_section_parameters_df, per_section_alignment_parameters_df, on="z_index", how="outer")
    if len(individual_tomogram_df) != len(per_section_parameters_df):
        raise ValueError(
            f"[Run {alignment.run_id}, TiltSeries {tiltseries.id}, Alignment {alignment.id}] Mismatch between CTF and alignment parameters after merge {len(individual_tomogram_df)} merged != {len(per_section_parameters_df)} CTF != {len(per_section_alignment_parameters_df)} alignment parameters."
        )

    # reorder rows and columns to match RELION format
    individual_tomogram_df.sort_values(by="acquisition_order", inplace=True)
    individual_tomogram_df["rlnMicrographName"] = individual_tomogram_df["acquisition_order"].apply(lambda x: f"{str(int(x))}@{TILTSERIES_MRCS_PLACEHOLDER}")
    individual_tomogram_df[TILTSERIES_URI_RELION_COLUMN] = tiltseries.s3_omezarr_dir
    individual_tomogram_df = individual_tomogram_df.drop(columns=["z_index", "acquisition_order"])
    individual_tomogram_df = individual_tomogram_df[INDIVIDUAL_TOMOGRAM_COLUMNS]

    # generate empty placeholder tiltseries mrc (relative path)
    with mrcfile.new(output_dir / TILTSERIES_MRCS_PLACEHOLDER, overwrite=True) as mrc:
        mrc.voxel_size = tiltseries.pixel_spacing
        mrc.header.nx = tiltseries.size_x
        mrc.header.ny = tiltseries.size_y
        mrc.header.nz = tiltseries.size_z

    if individual_tomogram_df.isna().any().any():
        raise ValueError(
            f"[Run {alignment.run_id}, TiltSeries {tiltseries.id}, Alignment {alignment.id}] Data contains NA values. This can cause issues with RELION subtomogram extraction. Please check the star file."
        )

    tomo_name = f"run_{alignment.run_id}_tiltseries_{tiltseries.id}_alignment_{alignment.id}_spacing_{voxel_spacing.id}"
    output_path = output_dir / "tiltseries" / f"{tomo_name}.star"
    starfile.write({tomo_name: individual_tomogram_df}, output_path, overwrite=True)
    logger.debug(f"[Run {alignment.run_id}, TiltSeries {tiltseries.id}, Alignment {alignment.id}] Wrote individual tomogram star file to {output_path}")

    return individual_tomogram_df, tomo_name


def generate_individual_tomogram_starfiles(alignment_and_voxel_spacing_ids: list[tuple[int, int]], output_dir: Path, use_tqdm: bool = True) -> list[pd.DataFrame]:
    """
    Generates individual tomogram star files for each tuple of alignment ID and voxel spacing ID.
    Args:
        alignment_and_voxel_spacing_ids (list[tuple[int, int]]): List of tuples containing alignment IDs and their corresponding voxel spacing IDs that specify the tomograms to generate.
        output_dir (Path): Directory where the individual tomogram star files will be saved.
        use_tqdm (bool): Whether to use tqdm for progress tracking (and print it out to the console).
    Returns:
        list[pd.DataFrame]: List of DataFrames containing the individual tomogram data.
    """
    logger.info(f"Generating individual tomogram star files in {output_dir} ...")
    all_alignments = cdp_cache.get_alignments([av[0] for av in alignment_and_voxel_spacing_ids]).values()
    all_voxel_spacings = cdp_cache.get_voxel_spacings([av[1] for av in alignment_and_voxel_spacing_ids]).values()

    if any(alignment is None for alignment in all_alignments) or any(voxel_spacing is None for voxel_spacing in all_voxel_spacings):
        raise ValueError("Some alignments or voxel spacings are missing. Ensure the alignment and voxel spacing IDs are valid.")

    individual_tomograms_dfs = []
    tomo_names = []

    with ThreadPoolExecutor(max_workers=THREAD_POOL_WORKER_COUNT) as thread_pool:
        futures = [thread_pool.submit(generate_individual_tomogram_starfile, alignment, voxel_spacing, output_dir) for alignment, voxel_spacing in zip(all_alignments, all_voxel_spacings)]

        pbar = tqdm(total=len(futures), desc="Generating individual tomogram star files") if use_tqdm else None
        for fut in as_completed(futures):
            individual_tomogram_df, tomo_name = fut.result()
            if individual_tomogram_df is not None:
                individual_tomograms_dfs.append(individual_tomogram_df)
                tomo_names.append(tomo_name)
            if pbar:
                pbar.update(1)

        if pbar:
            pbar.close()

    return individual_tomograms_dfs, tomo_names


def generate_starfiles_from_annotation_files(annotation_files: list[cdp.AnnotationFile], output_dir: Path, use_tqdm: bool = True) -> tuple[Path, Path]:
    """
    Generates particles.star, tomograms.star, and individual tomogram star files from the given annotation files.
    Args:
        annotation_files (list[cdp.AnnotationFile]): List of annotation files to generate star files from.
        output_dir (Path): Directory where the star files will be saved.
        use_tqdm (bool): Whether to use tqdm for progress tracking (and print it out to the console).
    Returns:
        tuple: A tuple containing the paths to the generated particles.star, tomograms.star, and the tiltseries folder.
    """
    start_time = time.time()
    optics_df, particles_df = get_particles_df_optics_df(annotation_files, use_tqdm=use_tqdm)
    tomograms_df, alignment_and_voxel_spacing_ids = get_tomograms_df(optics_df, particles_df)
    _, tomo_names = generate_individual_tomogram_starfiles(alignment_and_voxel_spacing_ids, output_dir, use_tqdm=use_tqdm)
    # filter out invalid tomograms from optics, particles, and tomograms dataframes
    particles_df = particles_df[particles_df["rlnTomoName"].isin(tomo_names)]
    tomograms_df = tomograms_df[tomograms_df["rlnTomoName"].isin(tomo_names)]
    particles_df_optics_groups = particles_df["rlnOpticsGroupName"].unique()
    tomograms_df_optics_groups = tomograms_df["rlnOpticsGroupName"].unique()
    if set(particles_df_optics_groups) != set(tomograms_df_optics_groups):
        raise ValueError(
            f"Optics groups in particles ({particles_df_optics_groups}) and tomograms ({tomograms_df_optics_groups}) do not match. This may cause issues with RELION subtomogram extraction."
        )
    optics_df = optics_df[optics_df["rlnOpticsGroupName"].isin(particles_df_optics_groups)]

    # write files
    particles_path = output_dir / "particles.star"
    tomograms_path = output_dir / "tomograms.star"
    tiltseries_folder_path = output_dir / "tiltseries"
    starfile.write({"optics": optics_df, "particles": particles_df}, particles_path, overwrite=True)
    starfile.write({"global": tomograms_df}, tomograms_path, overwrite=True)
    logger.info(f"Wrote {len(optics_df)} optics group(s) and {len(particles_df)} particle(s) to {output_dir / 'particles.star'}")
    logger.info(f"Wrote {len(tomograms_df)} tomogram(s) to {output_dir / 'tomograms.star'}")

    end_time = time.time()
    logger.info(f"Finished generating star files in {end_time - start_time:.2f} seconds.")

    return particles_path, tomograms_path, tiltseries_folder_path


# TODO: Implement tomogram_ids and tomogram_names filtering
# TODO: If these values get used by rest of script, cache them in cdp_cache
def resolve_annotation_files(
    deposition_ids: list[int] = None,
    deposition_titles: list[str] = None,
    dataset_ids: list[int] = None,
    dataset_titles: list[str] = None,
    organism_names: list[str] = None,
    cell_names: list[str] = None,
    run_ids: list[int] = None,
    run_names: list[str] = None,
    tiltseries_ids: list[int] = None,
    alignment_ids: list[int] = None,
    tomogram_ids: list[int] = None,
    tomogram_names: list[str] = None,
    annotation_ids: list[int] = None,
    annotation_names: list[str] = None,
    inexact_match: bool = False,
) -> list[cdp.AnnotationFile]:
    client = cdp.Client()

    # First filter with information related to the Annotation class
    annotation_query_filters = []

    def add_filter(values, field, label=""):
        """Helper to append filters depending on inexact_match."""
        if not values:
            return
        if inexact_match:
            if len(values) > 1:
                raise ValueError(f"Cannot use inexact match with multiple values for {label}. Please provide a single value.")
            annotation_query_filters.append(field.ilike(f"%{values[0]}%"))
            logger.debug(f"Finding similar {label}: {values} (case insensitive, includes partial matches)")
        else:
            annotation_query_filters.append(field._in(values))
            logger.debug(f"Filtering annotations by exact {label}: {values}")

    if deposition_ids:
        annotation_query_filters.append(cdp.Annotation.deposition_id._in(deposition_ids))
        logger.debug(f"Filtering annotations by deposition IDs: {deposition_ids}")
    add_filter(deposition_titles, cdp.Annotation.deposition.title,  "deposition titles")
    if dataset_ids:
        annotation_query_filters.append(cdp.Annotation.run.dataset_id._in(dataset_ids))
        logger.debug(f"Filtering annotations by dataset IDs: {dataset_ids}")
    add_filter(dataset_titles, cdp.Annotation.run.dataset.title, "dataset titles")
    add_filter(organism_names, cdp.Annotation.run.dataset.organism_name, "organism names")
    add_filter(cell_names, cdp.Annotation.run.dataset.cell_name, "cell names")
    if run_ids:
        annotation_query_filters.append(cdp.Annotation.run.id._in(run_ids))
        logger.debug(f"Filtering annotations by run IDs: {run_ids}")
    add_filter(run_names, cdp.Annotation.run.name, "run names")
    if annotation_ids:
        annotation_query_filters.append(cdp.Annotation.id._in(annotation_ids))
        logger.debug(f"Filtering annotations by annotation IDs: {annotation_ids}")
    add_filter(annotation_names, cdp.Annotation.object_name, "annotation names")

    # Then filter with information related to the AnnotationFile class
    annotation_files = []
    if tiltseries_ids:
        logger.debug(f"Filtering annotation files by tiltseries IDs: {tiltseries_ids}")
        tiltseries_list = cdp_cache.get_tiltseries(tiltseries_ids).values()
        if not tiltseries_list:
            raise ValueError(f"No tiltseries found for IDs: {tiltseries_ids}")

        temp_alignment_ids = []
        for tiltseries in tiltseries_list:
            for alignment in tiltseries.alignments:
                cdp_cache.alignment_cache[alignment.id] = alignment
                temp_alignment_ids.append(alignment.id)

        if not temp_alignment_ids:
            raise ValueError(f"No alignments found for tiltseries IDs: {tiltseries_ids}")

        if alignment_ids:
            alignment_ids = [aid for aid in alignment_ids if aid in temp_alignment_ids]  # restrict to provided alignment IDs
        else:
            alignment_ids = temp_alignment_ids
    if alignment_ids:
        annotation_files: list[cdp.AnnotationFile] = cdp.AnnotationFile.find(client, [cdp.AnnotationFile.alignment_id._in(alignment_ids)])
        if not annotation_files:
            raise ValueError(f"No annotation files found for alignment IDs: {alignment_ids}")

    # Combine the two filters together
    if not annotation_query_filters and not annotation_files:
        raise ValueError("No filters provided. Please provide at least one filter.")

    final_files = []
    # if there's no annotation query filters, we just return the annotation files
    if not annotation_query_filters:
        final_files = annotation_files
    else:
        annotations: list[cdp.Annotation] = cdp.Annotation.find(client, annotation_query_filters)
        if not annotations:
            raise ValueError("No annotations found matching the provided filters.")

        # if there is both annotation query filters and annotation files, we filter the annotation files by the annotations
        if not annotation_files:
            final_files = [af for af in annotation_files if af.annotation_shape.annotation_id in [a.id for a in annotations]]
        # if there is annotation query filters, but there isn't any annotation files, we just find all annotation files that belong to the annotations
        else:
            final_files = cdp.AnnotationFile.find(client, [cdp.AnnotationFile.annotation_shape.annotation_id._in([a.id for a in annotations])])

    final_files = [af for af in final_files if af.annotation_shape.shape_type in ["Point", "OrientedPoint"]]

    if not final_files:
        raise ValueError("No Points / Oriented Point annotation files found matching the provided filters.")

    logger.info(f"Found {len(final_files)} annotation files matching the provided filters.")
    return final_files


def generate_starfiles(
    output_dir: Path,
    deposition_ids: list[int] = None,
    deposition_titles: list[str] = None,
    dataset_ids: list[int] = None,
    dataset_titles: list[str] = None,
    organism_names: list[str] = None,
    cell_names: list[str] = None,
    run_ids: list[str] = None,
    run_names: list[str] = None,
    tiltseries_ids: list[int] = None,
    alignment_ids: list[int] = None,
    tomogram_ids: list[int] = None,
    tomogram_names: list[str] = None,
    annotation_ids: list[int] = None,
    annotation_names: list[str] = None,
    inexact_match: bool = False,
    debug: bool = False,
    use_tqdm: bool = True,
) -> tuple[Path, Path]:
    """
    Generates star files for annotations based on the specified filters. First resolves all annotation IDs based on the provided filters, then generates the star files given the resolved annotation IDs.
    Returns:
        tuple: A tuple containing the paths to the generated particles.star, tomograms.star, and the tiltseries folder.
    """
    if use_tqdm:
        handler = TqdmLoggingHandler()
        handler.setFormatter(logging.Formatter("%(asctime)s - %(levelname)s - %(message)s"))
        logger.addHandler(handler)
        logger.propagate = False

    if debug:
        logger.setLevel(logging.DEBUG)

    suppress_noisy_loggers(NOISY_LOGGERS)

    (output_dir / "tiltseries").mkdir(parents=True, exist_ok=True)

    annotation_files = resolve_annotation_files(
        deposition_ids=deposition_ids,
        deposition_titles=deposition_titles,
        dataset_ids=dataset_ids,
        dataset_titles=dataset_titles,
        organism_names=organism_names,
        cell_names=cell_names,
        run_ids=run_ids,
        run_names=run_names,
        tiltseries_ids=tiltseries_ids,
        alignment_ids=alignment_ids,
        tomogram_ids=tomogram_ids,
        tomogram_names=tomogram_names,
        annotation_ids=annotation_ids,
        annotation_names=annotation_names,
        inexact_match=inexact_match,
    )

    return generate_starfiles_from_annotation_files(annotation_files, output_dir, use_tqdm=use_tqdm)


def main():
    parser = argparse.ArgumentParser(description="Generate star files needed for subtomogram extraction from a CryoET Data Portal run.")
    args_common.add_data_portal_args(parser)
    parser.add_argument("--output-dir", type=Path, required=True, help="Directory where star files will be saved.")
    parser.add_argument("--debug", action="store_true", help="Enable debug logging.")

    args = parser.parse_args()

    data_portal_args = {arg_ref: getattr(args, arg_ref) for arg_ref in args_common.DATA_PORTAL_ARG_REFS}
    generate_starfiles(output_dir=args.output_dir, **data_portal_args, debug=args.debug, use_tqdm=True)


if __name__ == "__main__":
    main()

# Example usage:
# python generate/generate_starfile.py --run-ids 16463 --annotation-names ribosome --output-dir tests/output/data_portal_16363_ribosome
